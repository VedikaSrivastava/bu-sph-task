{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Loading pre-trained model...\n",
      "Starting training...\n",
      "Before layer 0: h.shape=torch.Size([6775, 1]), edge_index.shape=torch.Size([2, 15579]), edge_attr.shape=torch.Size([9, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 1 but got size 9 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m x, edge_index, edge_attr \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(device), batch\u001b[38;5;241m.\u001b[39medge_attr\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Forward pass with layer checkpointing\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_with_checkpointing(model, x, edge_index, edge_attr)\n\u001b[0;32m    111\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgraph_pred_linear(output)  \u001b[38;5;66;03m# Final prediction layer\u001b[39;00m\n\u001b[0;32m    112\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device))\n",
      "Cell \u001b[1;32mIn[25], line 94\u001b[0m, in \u001b[0;36mforward_with_checkpointing\u001b[1;34m(model, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model\u001b[38;5;241m.\u001b[39mgnns):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: h.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, edge_index.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, edge_attr.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_attr\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m     h \u001b[38;5;241m=\u001b[39m checkpoint(layer, h, edge_index, edge_attr)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: h.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py:17\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:482\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    479\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    481\u001b[0m         )\n\u001b[1;32m--> 482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CheckpointFunction\u001b[38;5;241m.\u001b[39mapply(function, preserve, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    484\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[0;32m    485\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    486\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\autograd\\function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:261\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[1;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[0;32m    258\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 261\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m run_function(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akalps\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\bu-sph-task\\pretrain_gnns\\bio\\model.py:157\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    155\u001b[0m self_loop_attr[:,\u001b[38;5;241m7\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# attribute for self-loop edge\u001b[39;00m\n\u001b[0;32m    156\u001b[0m self_loop_attr \u001b[38;5;241m=\u001b[39m self_loop_attr\u001b[38;5;241m.\u001b[39mto(edge_attr\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(edge_attr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 157\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((edge_attr, self_loop_attr), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    159\u001b[0m edge_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_encoder(edge_attr)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 1 but got size 9 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
    "from torch.utils.data import Subset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from pretrain_gnns.bio.model import GNN\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import numpy as np\n",
    "\n",
    "# Set the device to CUDA if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to load and process the .mat files into the correct format\n",
    "def load_data(file_path):\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    x = torch.tensor(data['attrb'].todense(), dtype=torch.float32)\n",
    "    edge_index = torch.tensor(data['network'].nonzero(), dtype=torch.long)\n",
    "\n",
    "    # Initialize edge_attr correctly\n",
    "    edge_attr_data = data['network'].data\n",
    "    num_edges = edge_index.size(1)\n",
    "    \n",
    "    # Assuming 9 features per edge\n",
    "    num_features = 9\n",
    "    \n",
    "    if len(edge_attr_data.shape) == 1:\n",
    "        edge_attr_data = edge_attr_data.reshape(-1, 1)  # Ensure it's a 2D array with shape [num_edges, 1]\n",
    "    \n",
    "    if edge_attr_data.shape[1] < num_features:\n",
    "        # Expand the features if necessary, here using zeros as placeholders for simplicity\n",
    "        edge_attr = torch.zeros((num_edges, num_features), dtype=torch.float32)\n",
    "        edge_attr[:, :edge_attr_data.shape[1]] = torch.tensor(edge_attr_data, dtype=torch.float32)\n",
    "    else:\n",
    "        edge_attr = torch.tensor(edge_attr_data, dtype=torch.float32)\n",
    "\n",
    "    y = torch.tensor(data['group'].argmax(axis=1).squeeze(), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "class CustomDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list):\n",
    "        super().__init__()\n",
    "        self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data.__class__(**{key: self.data[key][idx] for key in self.data.keys()})\n",
    "\n",
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "data_list = [load_data('acmv9.mat')]\n",
    "train_data = CustomDataset(data_list)\n",
    "test_data = load_data('citationv1.mat')\n",
    "\n",
    "# Check and reduce the training dataset to half if it's large enough\n",
    "dataset_size = len(train_data)\n",
    "if dataset_size > 1:\n",
    "    indices = np.random.choice(dataset_size, dataset_size // 2, replace=False)\n",
    "    train_data_reduced = Subset(train_data, indices)\n",
    "else:\n",
    "    train_data_reduced = train_data  # Use the full dataset if it's too small to be halved\n",
    "\n",
    "# Load the pre-trained GAT model\n",
    "print(\"Loading pre-trained model...\")\n",
    "model = GNN(num_layer=5, emb_dim=300, gnn_type='gat')  # Maintain the model architecture\n",
    "model.load_state_dict(torch.load('pretrain_gnns/bio/model_architecture/gat_supervised_masking.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# Setup the DataLoader with a smaller batch size\n",
    "train_loader = DataLoader(train_data_reduced, batch_size=1, shuffle=True)\n",
    "\n",
    "# Setup optimizer, loss, and gradient scaler for mixed precision\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Function to checkpoint each layer of the model manually\n",
    "def forward_with_checkpointing(model, x, edge_index, edge_attr):\n",
    "    # Ensure that the input tensors are correctly shaped\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.unsqueeze(-1)  # Reshape x to have shape [num_nodes, 1] if it's 1D\n",
    "\n",
    "    if len(edge_index.shape) == 1:\n",
    "        edge_index = edge_index.view(2, -1)  # Reshape edge_index to [2, num_edges]\n",
    "\n",
    "    if len(edge_attr.shape) == 1:\n",
    "        edge_attr = edge_attr.unsqueeze(-1)  # Reshape edge_attr to [num_edges, 1]\n",
    "\n",
    "    # Iterate over each layer in the model\n",
    "    h = x\n",
    "    for i, layer in enumerate(model.gnns):\n",
    "        print(f\"Before layer {i}: h.shape={h.shape}, edge_index.shape={edge_index.shape}, edge_attr.shape={edge_attr.shape}\")\n",
    "        h = checkpoint(layer, h, edge_index, edge_attr)\n",
    "        print(f\"After layer {i}: h.shape={h.shape}\")\n",
    "    return h\n",
    "\n",
    "# Training loop with manual layer checkpointing\n",
    "accumulation_steps = 10  # Smaller accumulation steps\n",
    "\n",
    "print(\"Starting training...\")\n",
    "model.train()\n",
    "for epoch in range(25):  # Adjust the number of epochs as needed\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        with autocast():\n",
    "            x, edge_index, edge_attr = batch.x.to(device), batch.edge_index.to(device), batch.edge_attr.to(device)\n",
    "            \n",
    "            # Forward pass with layer checkpointing\n",
    "            output = forward_with_checkpointing(model, x, edge_index, edge_attr)\n",
    "            output = model.graph_pred_linear(output)  # Final prediction layer\n",
    "            loss = criterion(output, batch.y.to(device))\n",
    "            loss = loss / accumulation_steps  # Scale loss for accumulation\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Step the optimizer every 'accumulation_steps' batches\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            torch.cuda.empty_cache()  # Clear cache to free up memory\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}')\n",
    "    torch.cuda.empty_cache()  # Clear cache to free up memory after each epoch\n",
    "\n",
    "# Evaluation\n",
    "print(\"Evaluating model...\")\n",
    "model.eval()\n",
    "with torch.no_grad():  # Disabling the dynamic graph for memory efficiency\n",
    "    x, edge_index, edge_attr, y = test_data.x.to(device), test_data.edge_index.to(device), test_data.edge_attr.to(device), test_data.y.to(device)\n",
    "    output = model(x, edge_index, edge_attr)\n",
    "    predictions = torch.argmax(output, dim=1)\n",
    "    accuracy = accuracy_score(y.cpu(), predictions.cpu())\n",
    "    micro_f1 = f1_score(y.cpu(), predictions.cpu(), average='micro')\n",
    "    print(f'Accuracy: {accuracy:.4f}, Micro F1 Score: {micro_f1:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
